# Cover Letter

## Journal Submission: ConvNeXt for Earthquake Precursor Detection

---

**Date**: [Submission Date]

**To**: Editor-in-Chief  
[Journal Name]

**Subject**: Submission of Original Research Article

---

Dear Editor,

We are pleased to submit our manuscript entitled **"Earthquake Precursor Detection using ConvNeXt: A Modern Convolutional Approach for ULF Geomagnetic Signal Classification"** for consideration for publication in [Journal Name].

### Research Significance

This study presents the **first application of ConvNeXt architecture** for earthquake precursor detection from Ultra-Low Frequency (ULF) geomagnetic signals. ConvNeXt, introduced in CVPR 2022, represents a significant advancement in convolutional neural network design by incorporating principles from Vision Transformers while maintaining computational efficiency.

### Key Contributions

1. **Novel Architecture Application**: First use of ConvNeXt for geophysical signal classification
2. **Multi-Task Learning**: Simultaneous magnitude and azimuth classification from spectrograms
3. **Comprehensive Validation**: Rigorous LOEO and LOSO cross-validation methods
4. **Model Comparison**: Systematic comparison with VGG16, EfficientNet-B0, and Xception
5. **Interpretability**: Grad-CAM analysis revealing physically meaningful feature attention

### Dataset and Methodology

Our study utilizes a comprehensive dataset of 1,972 spectrograms from Indonesian geomagnetic stations, covering earthquake events from 2018-2025. The ConvNeXt-Tiny model (28.6M parameters) was trained with modern optimization techniques including:
- AdamW optimizer with weight decay 0.05
- Cosine annealing learning rate schedule with warmup
- Class-weighted loss functions for imbalanced data

### Results Summary

Our ConvNeXt-Tiny model achieved the following results through rigorous LOEO 10-fold cross-validation:

- **Magnitude Classification Accuracy**: 97.53% ± 0.96%
- **Azimuth Classification Accuracy**: 69.30% ± 5.74%
- **Best Fold Performance**: 90.00% combined accuracy (Fold 9)
- **Consistency**: Low standard deviation indicates robust generalization

These results are comparable to EfficientNet-B0 (97.53% magnitude, 69.51% azimuth) while offering a more modern architectural design.

### Relevance to Journal Scope

This manuscript aligns with [Journal Name]'s focus on:
- Deep learning applications in geophysics
- Earthquake early warning systems
- Signal processing and pattern recognition
- Modern neural network architectures

### Ethical Considerations

- All data was collected from publicly operated geomagnetic stations
- No human subjects were involved
- Code and models will be made publicly available upon acceptance

### Author Contributions

- [Author 1]: Conceptualization, methodology, writing
- [Author 2]: Data collection, validation
- [Author 3]: Software development, visualization
- [Author 4]: Supervision, review

### Declarations

- **Conflicts of Interest**: None
- **Funding**: [Funding source]
- **Data Availability**: Available upon request
- **Code Availability**: GitHub repository (link upon acceptance)

### Suggested Reviewers

1. [Reviewer 1 Name], [Institution] - Expert in earthquake precursors
2. [Reviewer 2 Name], [Institution] - Expert in deep learning for geophysics
3. [Reviewer 3 Name], [Institution] - Expert in CNN architectures

### Conclusion

We believe this manuscript makes a significant contribution to the field of earthquake precursor detection by demonstrating the effectiveness of modern CNN architectures. The rigorous validation methodology and comprehensive model comparison provide valuable insights for both researchers and practitioners.

We confirm that this manuscript has not been published elsewhere and is not under consideration by another journal. All authors have approved the manuscript and agree with its submission to [Journal Name].

Thank you for considering our submission. We look forward to your response.

Sincerely,

[Corresponding Author Name]  
[Title/Position]  
[Institution]  
[Email]  
[Phone]

---

### Attachments

1. Manuscript (PDF/Word)
2. Supplementary Materials
3. Figures (high resolution)
4. Author declaration form
5. Conflict of interest statement
