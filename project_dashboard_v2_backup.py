#!/usr/bin/env python3
"""
EARTHQUAKE PREDICTION PROJECT DASHBOARD V2.0
Comprehensive Streamlit Dashboard with Production Model
Updated to use latest production model (v2.1, 98.94% accuracy)

Features:
- Home & Overview
- Dataset Analysis
- Model Architecture
- Training Results
- Performance Metrics
- Prekursor Scanner (INTEGRATED)
- Real-time Monitoring
- Documentation

Author: Earthquake Prediction Research Team
Date: 4 February 2026
Version: 2.1 (Production - Final Model)
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json
from datetime import datetime
import plotly.graph_objects as go
import plotly.express as px
import torch
import torch.nn as nn
from PIL import Image
import sys

# Add paths
sys.path.insert(0, str(Path(__file__).parent))

# Page configuration
st.set_page_config(
    page_title="Earthquake Prediction Dashboard V2.0",
    page_icon="üåç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        text-align: center;
        padding: 1rem;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #1f77b4;
    }
    .section-header {
        font-size: 1.8rem;
        font-weight: bold;
        color: #2c3e50;
        margin-top: 2rem;
        margin-bottom: 1rem;
        border-bottom: 3px solid #3498db;
        padding-bottom: 0.5rem;
    }
    .success-box {
        background-color: #d4edda;
        padding: 1rem;
        border-radius: 5px;
        border-left: 4px solid #28a745;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        padding: 1rem;
        border-radius: 5px;
        border-left: 4px solid #ffc107;
        margin: 1rem 0;
    }
    .info-box {
        background-color: #e8f4f8;
        padding: 1rem;
        border-radius: 5px;
        border-left: 4px solid #3498db;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Sidebar
st.sidebar.markdown("### üåç Earthquake Prediction System")
st.sidebar.markdown("**Version**: 2.1 (Production)")
st.sidebar.markdown("**Model**: VGG16 Multi-task (Final)")
st.sidebar.markdown("**Accuracy**: 98.94%")
st.sidebar.markdown("---")

menu = st.sidebar.radio(
    "üìã Navigation Menu",
    [
        "üè† Home & Overview",
        "üìä Dataset Analysis",
        "üß† Model Architecture",
        "üìà Training Results",
        "üéØ Performance Metrics",
        "‚úÖ Hasil Validasi Model",
        "üî¨ Model Comparison",
        "üîç Prekursor Scanner",
        "üì° Real-time Monitoring",
        "üìñ Documentation"
    ]
)

st.sidebar.markdown("---")
st.sidebar.markdown("### üìå System Info")
st.sidebar.info("""
**Model**: v2.1 (Final Production)

**Performance**:
- Magnitude: 98.94%
- Normal: 100.00%
- Azimuth: 83.92%

**Validation (LOEO/LOSO)**:
- LOEO Mag: 97.53%
- LOSO Mag: 97.57%

**Status**: ‚úÖ PRODUCTION

**Data**: No leakage (0 overlaps)
""")

# Load data functions
@st.cache_data
def load_production_config():
    """Load production config"""
    try:
        with open('production/config/production_config.json', 'r') as f:
            return json.load(f)
    except:
        return None

@st.cache_data
def load_training_history():
    """Load training history from fixed model"""
    try:
        df = pd.read_csv('experiments_fixed/exp_fixed_20260202_163643/training_history.csv')
        return df
    except:
        return None

@st.cache_data
def load_dataset_metadata():
    """Load dataset metadata"""
    try:
        df = pd.read_csv('dataset_unified/metadata/unified_metadata.csv')
        return df
    except:
        return None

@st.cache_data
def load_class_mappings():
    """Load class mappings"""
    try:
        with open('production/config/class_mappings.json', 'r') as f:
            return json.load(f)
    except:
        return None

# Main header
st.markdown('<div class="main-header">üåç EARTHQUAKE PREDICTION DASHBOARD V2.1</div>', unsafe_allow_html=True)
st.markdown("### Multi-Task CNN for ULF Geomagnetic Earthquake Precursor Detection")
st.markdown("**Production Model** | Version 2.1 | 98.94% Accuracy | LOEO/LOSO Validated")

# ============================================================================
# HOME & OVERVIEW
# ============================================================================
if menu == "üè† Home & Overview":
    st.markdown('<div class="section-header">üìä System Overview</div>', unsafe_allow_html=True)
    
    config = load_production_config()
    
    # Metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown('<div class="metric-card">', unsafe_allow_html=True)
        st.metric("Model Version", "2.1", "Final Production")
        st.markdown('</div>', unsafe_allow_html=True)
    
    with col2:
        st.markdown('<div class="metric-card">', unsafe_allow_html=True)
        if config:
            acc = config['performance_metrics']['test_magnitude_accuracy']
            st.metric("Test Accuracy", f"{acc}%", "‚úÖ Excellent")
        else:
            st.metric("Test Accuracy", "98.94%", "‚úÖ Excellent")
        st.markdown('</div>', unsafe_allow_html=True)
    
    with col3:
        st.markdown('<div class="metric-card">', unsafe_allow_html=True)
        st.metric("Data Leakage", "0", "‚úÖ Fixed")
        st.markdown('</div>', unsafe_allow_html=True)
    
    with col4:
        st.markdown('<div class="metric-card">', unsafe_allow_html=True)
        st.metric("Status", "PRODUCTION", "‚úÖ Active")
        st.markdown('</div>', unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Performance Summary
    if config:
        st.markdown('<div class="section-header">üéØ Performance Summary</div>', unsafe_allow_html=True)
        
        perf = config['performance_metrics']
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown('<div class="success-box">', unsafe_allow_html=True)
            st.markdown(f"""
            **‚úÖ Magnitude Classification**
            - Test Accuracy: **{perf['test_magnitude_accuracy']}%**
            - Status: **EXCELLENT**
            - Target: 90% (Achieved ‚úÖ)
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="success-box">', unsafe_allow_html=True)
            st.markdown(f"""
            **‚úÖ Normal Class Detection**
            - Test Accuracy: **{perf['test_normal_accuracy']}%**
            - Status: **PERFECT**
            - Critical for false alarm reduction
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        st.markdown('<div class="warning-box">', unsafe_allow_html=True)
        st.markdown(f"""
        **‚ö†Ô∏è Azimuth Classification**
        - Test Accuracy: **{perf['test_azimuth_accuracy']}%**
        - Status: **MODERATE** (Expected - challenging task)
        - Note: Azimuth is inherently difficult due to complex geomagnetic patterns
        """)
        st.markdown('</div>', unsafe_allow_html=True)
    
    # Key Features
    st.markdown('<div class="section-header">üèÜ Key Features</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown('<div class="info-box">', unsafe_allow_html=True)
        st.markdown("""
        **‚úÖ Technical Achievements**
        - VGG16 Multi-task Architecture
        - Fixed data split (by station+date)
        - No data leakage (0 overlaps)
        - PyTorch implementation
        - Production-ready deployment
        """)
        st.markdown('</div>', unsafe_allow_html=True)
    
    with col2:
        st.markdown('<div class="info-box">', unsafe_allow_html=True)
        st.markdown("""
        **üìä System Capabilities**
        - Real-time earthquake prediction
        - Multi-station monitoring
        - Automated scanning
        - Performance tracking
        - Web-based dashboard
        """)
        st.markdown('</div>', unsafe_allow_html=True)

# ============================================================================
# DATASET ANALYSIS
# ============================================================================
elif menu == "üìä Dataset Analysis":
    st.markdown('<div class="section-header">üìä Dataset Analysis</div>', unsafe_allow_html=True)
    
    metadata_df = load_dataset_metadata()
    
    if metadata_df is not None:
        # Statistics
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown('<div class="info-box">', unsafe_allow_html=True)
            st.markdown(f"""
            **üìà Dataset Size**
            - Total Samples: {len(metadata_df):,}
            - Earthquake Events: {len(metadata_df[metadata_df['magnitude_class'] != 'Normal']):,}
            - Normal Events: {len(metadata_df[metadata_df['magnitude_class'] == 'Normal']):,}
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="info-box">', unsafe_allow_html=True)
            st.markdown(f"""
            **üó∫Ô∏è Coverage**
            - Stations: {metadata_df['station'].nunique()}
            - Date Range: {metadata_df['date'].min()} to {metadata_df['date'].max()}
            - Temporal Span: 6+ years
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col3:
            st.markdown('<div class="info-box">', unsafe_allow_html=True)
            st.markdown(f"""
            **üéØ Classes**
            - Magnitude: {metadata_df['magnitude_class'].nunique()}
            - Azimuth: {metadata_df['azimuth_class'].nunique()}
            - Multi-task: ‚úÖ
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        st.markdown("---")
        
        # Class distribution
        st.markdown("### üìä Class Distribution")
        
        # Image size control
        viz_size = st.radio(
            "Visualization Size",
            ["Large", "Medium", "Small"],
            horizontal=True,
            index=0
        )
        
        if viz_size == "Large":
            chart_height = 600
        elif viz_size == "Medium":
            chart_height = 400
        else:
            chart_height = 300
        
        col1, col2 = st.columns(2)
        
        with col1:
            mag_counts = metadata_df['magnitude_class'].value_counts()
            fig = go.Figure(data=[go.Pie(
                labels=mag_counts.index,
                values=mag_counts.values,
                hole=0.4
            )])
            fig.update_layout(title="Magnitude Distribution", height=chart_height)
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            az_counts = metadata_df['azimuth_class'].value_counts()
            fig = go.Figure(data=[go.Bar(
                x=az_counts.index,
                y=az_counts.values
            )])
            fig.update_layout(title="Azimuth Distribution", height=chart_height)
            st.plotly_chart(fig, use_container_width=True)
    else:
        st.error("‚ùå Dataset metadata not found")

# ============================================================================
# MODEL ARCHITECTURE
# ============================================================================
elif menu == "üß† Model Architecture":
    st.markdown('<div class="section-header">üß† Model Architecture</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### üèóÔ∏è VGG16 Multi-task Architecture")
        st.code("""
EarthquakeCNN V2.0 (Production):
‚îú‚îÄ‚îÄ VGG16 Backbone (Pretrained)
‚îÇ   ‚îú‚îÄ‚îÄ Conv Blocks (5 blocks)
‚îÇ   ‚îú‚îÄ‚îÄ MaxPooling layers
‚îÇ   ‚îî‚îÄ‚îÄ Feature extraction
‚îú‚îÄ‚îÄ Shared Feature Processing
‚îÇ   ‚îú‚îÄ‚îÄ Flatten
‚îÇ   ‚îú‚îÄ‚îÄ Dense 4096
‚îÇ   ‚îú‚îÄ‚îÄ Dropout 0.5
‚îÇ   ‚îî‚îÄ‚îÄ Dense 4096
‚îî‚îÄ‚îÄ Task-Specific Heads
    ‚îú‚îÄ‚îÄ Magnitude Head (4 classes)
    ‚îî‚îÄ‚îÄ Azimuth Head (9 classes)

Total Parameters: ~138M
Model Size: ~528 MB
Inference Time: ~100ms per sample
        """)
    
    with col2:
        st.markdown("### üìä Model Stats")
        st.metric("Parameters", "138M", "Trainable")
        st.metric("Model Size", "528 MB", "PyTorch")
        st.metric("Inference", "100 ms", "CPU")
        st.metric("Input Size", "224√ó224", "RGB")
    
    st.markdown("---")
    
    # Training config
    st.markdown("### ‚öôÔ∏è Training Configuration")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("**Optimizer**")
        st.code("""
Optimizer: Adam
Learning Rate: 0.0001
Weight Decay: 0.0001
Batch Size: 32
Epochs: 11 (early stop)
        """)
    
    with col2:
        st.markdown("**Loss Function**")
        st.code("""
Loss: CrossEntropyLoss
Task Weights: Equal
Label Smoothing: 0.1
Reduction: Mean
        """)
    
    with col3:
        st.markdown("**Data Split**")
        st.code("""
Method: By station+date
Train: 1,384 samples
Val: 284 samples
Test: 304 samples
Overlap: 0 (Fixed!)
        """)

# ============================================================================
# TRAINING RESULTS
# ============================================================================
elif menu == "üìà Training Results":
    st.markdown('<div class="section-header">üìà Training Results</div>', unsafe_allow_html=True)
    
    history_df = load_training_history()
    
    if history_df is not None:
        # Summary
        col1, col2, col3, col4 = st.columns(4)
        
        final_epoch = history_df.iloc[-1]
        
        with col1:
            st.metric("Total Epochs", len(history_df), "Early stopped")
        
        with col2:
            st.metric("Final Val Loss", f"{final_epoch['val_loss']:.4f}")
        
        with col3:
            # Handle different column names
            mag_acc_col = 'val_mag_acc' if 'val_mag_acc' in final_epoch else 'val_magnitude_acc'
            st.metric("Magnitude Acc", f"{final_epoch[mag_acc_col]*100:.2f}%")
        
        with col4:
            # Handle different column names
            azi_acc_col = 'val_azi_acc' if 'val_azi_acc' in final_epoch else 'val_azimuth_acc'
            st.metric("Azimuth Acc", f"{final_epoch[azi_acc_col]*100:.2f}%")
        
        st.markdown("---")
        
        # Chart size control
        st.markdown("### üìä Visualization Controls")
        chart_size = st.select_slider(
            "Chart Size",
            options=["Small (400px)", "Medium (600px)", "Large (800px)", "Extra Large (1000px)"],
            value="Large (800px)"
        )
        
        if "Small" in chart_size:
            chart_height = 400
        elif "Medium" in chart_size:
            chart_height = 600
        elif "Large" in chart_size:
            chart_height = 800
        else:
            chart_height = 1000
        
        # Loss curves
        st.markdown("### üìâ Loss Curves")
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=history_df.index + 1,  # Epoch starts from 1
            y=history_df['train_loss'],
            mode='lines+markers',
            name='Training Loss',
            line=dict(width=3)
        ))
        fig.add_trace(go.Scatter(
            x=history_df.index + 1,
            y=history_df['val_loss'],
            mode='lines+markers',
            name='Validation Loss',
            line=dict(width=3)
        ))
        fig.update_layout(
            title="Training Progress",
            height=chart_height,
            xaxis_title="Epoch",
            yaxis_title="Loss",
            hovermode='x unified'
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Accuracy curves
        st.markdown("### üéØ Accuracy Progression")
        
        col1, col2 = st.columns(2)
        
        # Determine column names
        train_mag_col = 'train_mag_acc' if 'train_mag_acc' in history_df.columns else 'train_magnitude_acc'
        val_mag_col = 'val_mag_acc' if 'val_mag_acc' in history_df.columns else 'val_magnitude_acc'
        train_azi_col = 'train_azi_acc' if 'train_azi_acc' in history_df.columns else 'train_azimuth_acc'
        val_azi_col = 'val_azi_acc' if 'val_azi_acc' in history_df.columns else 'val_azimuth_acc'
        
        with col1:
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=history_df.index + 1,
                y=history_df[train_mag_col]*100,
                mode='lines+markers',
                name='Train',
                line=dict(width=3)
            ))
            fig.add_trace(go.Scatter(
                x=history_df.index + 1,
                y=history_df[val_mag_col]*100,
                mode='lines+markers',
                name='Validation',
                line=dict(width=3)
            ))
            fig.update_layout(
                title="Magnitude Accuracy",
                height=chart_height,
                xaxis_title="Epoch",
                yaxis_title="Accuracy (%)",
                hovermode='x unified'
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=history_df.index + 1,
                y=history_df[train_azi_col]*100,
                mode='lines+markers',
                name='Train',
                line=dict(width=3)
            ))
            fig.add_trace(go.Scatter(
                x=history_df.index + 1,
                y=history_df[val_azi_col]*100,
                mode='lines+markers',
                name='Validation',
                line=dict(width=3)
            ))
            fig.update_layout(
                title="Azimuth Accuracy",
                height=chart_height,
                xaxis_title="Epoch",
                yaxis_title="Accuracy (%)",
                hovermode='x unified'
            )
            st.plotly_chart(fig, use_container_width=True)
    else:
        st.error("‚ùå Training history not found")

# ============================================================================
# PERFORMANCE METRICS
# ============================================================================
elif menu == "üéØ Performance Metrics":
    st.markdown('<div class="section-header">üéØ Performance Metrics</div>', unsafe_allow_html=True)
    
    config = load_production_config()
    
    if config:
        perf = config['performance_metrics']
        
        # Test metrics
        st.markdown("### üìä Test Set Performance")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown('<div class="success-box">', unsafe_allow_html=True)
            st.markdown(f"""
            **Magnitude Classification**
            - Accuracy: **{perf['test_magnitude_accuracy']}%**
            - Status: ‚úÖ EXCELLENT
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="success-box">', unsafe_allow_html=True)
            st.markdown(f"""
            **Normal Detection**
            - Accuracy: **{perf['test_normal_accuracy']}%**
            - Status: ‚úÖ PERFECT
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col3:
            st.markdown('<div class="warning-box">', unsafe_allow_html=True)
            st.markdown(f"""
            **Azimuth Classification**
            - Accuracy: **{perf['test_azimuth_accuracy']}%**
            - Status: ‚ö†Ô∏è MODERATE
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        st.markdown("---")
        
        # Validation metrics
        st.markdown("### üìà Validation Performance")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown('<div class="info-box">', unsafe_allow_html=True)
            st.markdown(f"""
            **Detection Rate**
            - Rate: **{perf['validation_detection_rate']}%**
            - All earthquakes detected ‚úÖ
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="info-box">', unsafe_allow_html=True)
            st.markdown(f"""
            **Magnitude Accuracy**
            - Accuracy: **{perf['validation_magnitude_accuracy']}%**
            - High precision ‚úÖ
            """)
            st.markdown('</div>', unsafe_allow_html=True)
    else:
        st.error("‚ùå Config not found")

# ============================================================================
# HASIL VALIDASI MODEL
# ============================================================================
elif menu == "‚úÖ Hasil Validasi Model":
    st.markdown('<div class="section-header">‚úÖ Hasil Validasi Model</div>', unsafe_allow_html=True)
    
    st.markdown("""
    **Comprehensive Model Validation Results**
    
    Halaman ini menampilkan hasil validasi model secara lengkap termasuk:
    - **LOEO (Leave-One-Event-Out)**: Validasi dengan menyisakan satu event gempa
    - **LOSO (Leave-One-Station-Out)**: Validasi dengan menyisakan satu stasiun
    - **Grad-CAM**: Visualisasi area fokus model pada spectrogram
    """)
    
    # Validation summary
    st.markdown("### üìä Ringkasan Validasi")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown('<div class="success-box">', unsafe_allow_html=True)
        st.markdown("""
        **LOEO Validation (10-Fold)**
        - Magnitude: **97.53% ¬± 0.96%**
        - Azimuth: **69.51% ¬± 5.65%**
        - Status: ‚úÖ VALIDATED
        """)
        st.markdown('</div>', unsafe_allow_html=True)
    
    with col2:
        st.markdown('<div class="success-box">', unsafe_allow_html=True)
        st.markdown("""
        **LOSO Validation (9-Fold)**
        - Magnitude: **97.57%** (weighted)
        - Azimuth: **69.73%** (weighted)
        - Status: ‚úÖ VALIDATED
        """)
        st.markdown('</div>', unsafe_allow_html=True)
    
    with col3:
        st.markdown('<div class="info-box">', unsafe_allow_html=True)
        st.markdown("""
        **Grad-CAM Analysis**
        - VGG16 vs EfficientNet
        - 3 Sample Events
        - Status: ‚úÖ COMPLETE
        """)
        st.markdown('</div>', unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Tab selection for different validation types
    validation_tab = st.selectbox(
        "Pilih Jenis Validasi",
        ["üìà LOEO Validation", "üó∫Ô∏è LOSO Validation", "üî• Grad-CAM Visualization", "üìä Model Comparison", "üìâ Performance Metrics"],
        index=0
    )
    
    # Image size control
    img_size = st.radio(
        "Ukuran Gambar",
        ["Full Width", "Large (1200px)", "Medium (800px)", "Small (600px)"],
        horizontal=True,
        index=0
    )
    
    st.markdown("---")
    
    # ==================== LOEO VALIDATION ====================
    if validation_tab == "üìà LOEO Validation":
        st.markdown("### üìà LOEO (Leave-One-Event-Out) Validation")
        
        st.markdown("""
        **Metodologi**: Model dilatih dengan menyisakan satu event gempa untuk testing.
        Proses diulang untuk setiap event (10 fold) untuk memastikan model dapat 
        menggeneralisasi ke event gempa yang belum pernah dilihat.
        """)
        
        # Load LOEO results
        try:
            with open('loeo_validation_results/loeo_final_results.json', 'r') as f:
                loeo_results = json.load(f)
            
            # Display per-fold results
            st.markdown("#### üìä Hasil Per-Fold")
            
            fold_data = []
            for fold in loeo_results.get('per_fold_results', []):
                fold_data.append({
                    'Fold': fold['fold'],
                    'Train Events': fold['n_train_events'],
                    'Test Events': fold['n_test_events'],
                    'Mag Acc (%)': f"{fold['magnitude_accuracy']:.2f}",
                    'Azi Acc (%)': f"{fold['azimuth_accuracy']:.2f}"
                })
            
            if fold_data:
                df_folds = pd.DataFrame(fold_data)
                st.dataframe(df_folds, use_container_width=True)
            
            # Summary statistics
            st.markdown("#### üìà Statistik Ringkasan")
            
            col1, col2 = st.columns(2)
            
            with col1:
                mag_stats = loeo_results.get('magnitude_accuracy', {})
                st.markdown(f"""
                **Magnitude Classification**
                - Mean: **{mag_stats.get('mean', 0):.2f}%**
                - Std: **{mag_stats.get('std', 0):.2f}%**
                - Min: {mag_stats.get('min', 0):.2f}%
                - Max: {mag_stats.get('max', 0):.2f}%
                """)
            
            with col2:
                azi_stats = loeo_results.get('azimuth_accuracy', {})
                st.markdown(f"""
                **Azimuth Classification**
                - Mean: **{azi_stats.get('mean', 0):.2f}%**
                - Std: **{azi_stats.get('std', 0):.2f}%**
                - Min: {azi_stats.get('min', 0):.2f}%
                - Max: {azi_stats.get('max', 0):.2f}%
                """)
        
        except Exception as e:
            st.warning(f"Could not load LOEO results: {e}")
        
        st.markdown("---")
        st.markdown("#### üìä Visualisasi LOEO")
        
        # LOEO Images
        loeo_images = [
            ('loeo_validation_results/loeo_per_fold_accuracy.png', 'Per-Fold Accuracy'),
            ('loeo_validation_results/loeo_boxplot.png', 'Accuracy Distribution (Boxplot)'),
            ('loeo_validation_results/loeo_comparison_chart.png', 'Comparison Chart'),
            ('loeo_validation_results/validation_method_comparison.png', 'Validation Method Comparison')
        ]
        
        for img_path, title in loeo_images:
            if Path(img_path).exists():
                st.markdown(f"**{title}**")
                if img_size == "Full Width":
                    st.image(img_path, use_container_width=True)
                elif img_size == "Large (1200px)":
                    st.image(img_path, width=1200)
                elif img_size == "Medium (800px)":
                    st.image(img_path, width=800)
                else:
                    st.image(img_path, width=600)
                st.markdown("---")
    
    # ==================== LOSO VALIDATION ====================
    elif validation_tab == "üó∫Ô∏è LOSO Validation":
        st.markdown("### üó∫Ô∏è LOSO (Leave-One-Station-Out) Validation")
        
        st.markdown("""
        **Metodologi**: Model dilatih dengan menyisakan satu stasiun untuk testing.
        Proses diulang untuk setiap stasiun (9 fold) untuk memastikan model dapat 
        menggeneralisasi ke lokasi geografis yang berbeda.
        """)
        
        # Load LOSO results
        try:
            with open('loso_validation_results/loso_final_results.json', 'r') as f:
                loso_results = json.load(f)
            
            # Display per-station results
            st.markdown("#### üìä Hasil Per-Stasiun")
            
            station_data = []
            for fold in loso_results.get('per_fold_results', []):
                station_data.append({
                    'Fold': fold['fold'],
                    'Station': fold['test_station'],
                    'Samples': fold['n_test_samples'],
                    'Mag Acc (%)': f"{fold['magnitude_accuracy']:.2f}",
                    'Azi Acc (%)': f"{fold['azimuth_accuracy']:.2f}"
                })
            
            if station_data:
                df_stations = pd.DataFrame(station_data)
                st.dataframe(df_stations, use_container_width=True)
            
            # Summary statistics
            st.markdown("#### üìà Statistik Ringkasan")
            
            col1, col2 = st.columns(2)
            
            with col1:
                mag_stats = loso_results.get('magnitude_accuracy', {})
                st.markdown(f"""
                **Magnitude Classification**
                - Weighted Mean: **{mag_stats.get('weighted_mean', 0):.2f}%**
                - Simple Mean: {mag_stats.get('mean', 0):.2f}%
                - Std: {mag_stats.get('std', 0):.2f}%
                """)
            
            with col2:
                azi_stats = loso_results.get('azimuth_accuracy', {})
                st.markdown(f"""
                **Azimuth Classification**
                - Weighted Mean: **{azi_stats.get('weighted_mean', 0):.2f}%**
                - Simple Mean: {azi_stats.get('mean', 0):.2f}%
                - Std: {azi_stats.get('std', 0):.2f}%
                """)
            
            # Station performance chart
            st.markdown("#### üìä Performa Per-Stasiun")
            
            if station_data:
                df_chart = pd.DataFrame(station_data)
                df_chart['Mag Acc (%)'] = df_chart['Mag Acc (%)'].astype(float)
                df_chart['Azi Acc (%)'] = df_chart['Azi Acc (%)'].astype(float)
                
                fig = go.Figure()
                fig.add_trace(go.Bar(
                    name='Magnitude',
                    x=df_chart['Station'],
                    y=df_chart['Mag Acc (%)'],
                    marker_color='#3498db'
                ))
                fig.add_trace(go.Bar(
                    name='Azimuth',
                    x=df_chart['Station'],
                    y=df_chart['Azi Acc (%)'],
                    marker_color='#e74c3c'
                ))
                fig.update_layout(
                    title='LOSO Validation: Accuracy per Station',
                    xaxis_title='Station',
                    yaxis_title='Accuracy (%)',
                    barmode='group',
                    height=500
                )
                st.plotly_chart(fig, use_container_width=True)
        
        except Exception as e:
            st.warning(f"Could not load LOSO results: {e}")
        
        st.markdown("---")
        st.markdown("#### üìä Visualisasi LOSO")
        
        # LOSO Images
        loso_images = [
            ('loso_validation_results/loso_per_station_accuracy.png', 'Per-Station Accuracy'),
            ('loso_validation_results/loso_boxplot.png', 'Accuracy Distribution (Boxplot)'),
            ('loso_validation_results/loso_sample_distribution.png', 'Sample Distribution per Station'),
            ('loso_validation_results/loeo_vs_loso_comparison.png', 'LOEO vs LOSO Comparison'),
            ('loso_validation_results/loso_summary_figure.png', 'LOSO Summary Figure')
        ]
        
        for img_path, title in loso_images:
            if Path(img_path).exists():
                st.markdown(f"**{title}**")
                if img_size == "Full Width":
                    st.image(img_path, use_container_width=True)
                elif img_size == "Large (1200px)":
                    st.image(img_path, width=1200)
                elif img_size == "Medium (800px)":
                    st.image(img_path, width=800)
                else:
                    st.image(img_path, width=600)
                st.markdown("---")
        
        st.markdown("#### üó∫Ô∏è Interpretasi Geografis")
        
        st.markdown("""
        **Kesimpulan LOSO**:
        - Model menunjukkan performa konsisten di berbagai stasiun
        - Tidak ada stasiun dengan performa sangat rendah
        - Model dapat digeneralisasi ke lokasi geografis baru
        """)
    
    # ==================== GRAD-CAM VISUALIZATION ====================
    elif validation_tab == "üî• Grad-CAM Visualization":
        st.markdown("### üî• Grad-CAM (Gradient-weighted Class Activation Mapping)")
        
        st.markdown("""
        **Metodologi**: Grad-CAM menunjukkan area pada spectrogram yang paling 
        berpengaruh terhadap keputusan klasifikasi model. Area merah/kuning 
        menunjukkan fokus tinggi, area biru menunjukkan fokus rendah.
        """)
        
        # Sub-selection for Grad-CAM
        gradcam_type = st.radio(
            "Pilih Tipe Visualisasi",
            ["VGG16 Grad-CAM", "EfficientNet Grad-CAM", "Perbandingan VGG16 vs EfficientNet"],
            horizontal=True
        )
        
        st.markdown("---")
        
        if gradcam_type == "VGG16 Grad-CAM":
            st.markdown("#### üî• VGG16 Grad-CAM Visualizations")
            
            vgg_images = [
                ('visualization_gradcam/Large_MLB_2021-04-16_visualization.png', 
                 'Large Earthquake - MLB Station (2021-04-16)'),
                ('visualization_gradcam/Medium_SCN_2018-01-17_visualization.png', 
                 'Medium Earthquake - SCN Station (2018-01-17)'),
                ('visualization_gradcam/Moderate_SCN_2018-10-29_visualization.png', 
                 'Moderate Earthquake - SCN Station (2018-10-29)')
            ]
            
            for img_path, title in vgg_images:
                if Path(img_path).exists():
                    st.markdown(f"**{title}**")
                    if img_size == "Full Width":
                        st.image(img_path, use_container_width=True)
                    elif img_size == "Large (1200px)":
                        st.image(img_path, width=1200)
                    elif img_size == "Medium (800px)":
                        st.image(img_path, width=800)
                    else:
                        st.image(img_path, width=600)
                    st.markdown("---")
        
        elif gradcam_type == "EfficientNet Grad-CAM":
            st.markdown("#### üî• EfficientNet Grad-CAM Visualizations")
            
            eff_images = [
                ('visualization_gradcam_efficientnet/Large_MLB_2021-04-16_visualization.png', 
                 'Large Earthquake - MLB Station (2021-04-16)'),
                ('visualization_gradcam_efficientnet/Medium_SCN_2018-01-17_visualization.png', 
                 'Medium Earthquake - SCN Station (2018-01-17)'),
                ('visualization_gradcam_efficientnet/Moderate_SCN_2018-10-29_visualization.png', 
                 'Moderate Earthquake - SCN Station (2018-10-29)')
            ]
            
            for img_path, title in eff_images:
                if Path(img_path).exists():
                    st.markdown(f"**{title}**")
                    if img_size == "Full Width":
                        st.image(img_path, use_container_width=True)
                    elif img_size == "Large (1200px)":
                        st.image(img_path, width=1200)
                    elif img_size == "Medium (800px)":
                        st.image(img_path, width=800)
                    else:
                        st.image(img_path, width=600)
                    st.markdown("---")
        
        else:  # Comparison
            st.markdown("#### üî• Perbandingan VGG16 vs EfficientNet")
            
            comparison_images = [
                ('gradcam_comparison/Large_MLB_2021-04-16_comparison.png', 
                 'Large Earthquake - MLB Station (2021-04-16)'),
                ('gradcam_comparison/Medium_SCN_2018-01-17_comparison.png', 
                 'Medium Earthquake - SCN Station (2018-01-17)'),
                ('gradcam_comparison/Moderate_SCN_2018-10-29_comparison.png', 
                 'Moderate Earthquake - SCN Station (2018-10-29)'),
                ('gradcam_comparison/confidence_comparison.png', 
                 'Confidence Comparison')
            ]
            
            for img_path, title in comparison_images:
                if Path(img_path).exists():
                    st.markdown(f"**{title}**")
                    if img_size == "Full Width":
                        st.image(img_path, use_container_width=True)
                    elif img_size == "Large (1200px)":
                        st.image(img_path, width=1200)
                    elif img_size == "Medium (800px)":
                        st.image(img_path, width=800)
                    else:
                        st.image(img_path, width=600)
                    st.markdown("---")
        
        # Grad-CAM interpretation
        st.markdown("#### üìù Interpretasi Grad-CAM")
        
        st.markdown("""
        **Temuan Utama**:
        1. **VGG16** fokus pada pola frekuensi rendah (0.01-0.05 Hz) yang konsisten dengan teori ULF precursor
        2. **EfficientNet** menunjukkan pola fokus yang lebih tersebar
        3. Kedua model fokus pada periode 1-7 hari sebelum gempa (precursor window)
        4. Area fokus berbeda untuk magnitude berbeda, menunjukkan model belajar fitur yang relevan
        """)
    
    # ==================== MODEL COMPARISON ====================
    elif validation_tab == "üìä Model Comparison":
        st.markdown("### üìä Model Comparison (VGG16 vs EfficientNet)")
        
        st.markdown("""
        **Perbandingan komprehensif** antara arsitektur VGG16 dan EfficientNet-B0 
        untuk deteksi prekursor gempa bumi menggunakan spectrogram ULF.
        """)
        
        # Summary comparison
        st.markdown("#### üèÜ Ringkasan Perbandingan")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown('<div class="success-box">', unsafe_allow_html=True)
            st.markdown("""
            **VGG16 (Production Model)**
            - Magnitude Accuracy: **98.94%** ‚úÖ
            - Azimuth Accuracy: **83.92%**
            - LOEO Validation: **97.53%**
            - Model Size: 528 MB
            - Inference Time: ~125 ms
            - Status: **DEPLOYED**
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="info-box">', unsafe_allow_html=True)
            st.markdown("""
            **EfficientNet-B0**
            - Magnitude Accuracy: **94.37%**
            - Azimuth Accuracy: **57.39%**
            - LOEO Validation: **97.53%**
            - Model Size: 20 MB (26√ó smaller)
            - Inference Time: ~50 ms (2.5√ó faster)
            - Status: Alternative
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        st.markdown("---")
        st.markdown("#### üìä Visualisasi Perbandingan Model")
        
        # Model comparison images from paper_figures
        comparison_images = [
            ('paper_figures/fig5_model_comparison.png', 'Model Performance Comparison'),
            ('paper_figures/fig2_architecture_comparison.png', 'Architecture Comparison'),
            ('paper_figures/fig3_training_curves.png', 'Training Curves Comparison'),
            ('paper_figures/fig4_confusion_matrices.png', 'Confusion Matrices'),
            ('paper_figures/fig6_per_class_performance.png', 'Per-Class Performance'),
            ('q1_comprehensive_report/fig6_model_comparison.png', 'Comprehensive Model Comparison'),
            ('q1_comprehensive_report/fig3_ablation_study.png', 'Ablation Study'),
        ]
        
        for img_path, title in comparison_images:
            if Path(img_path).exists():
                st.markdown(f"**{title}**")
                if img_size == "Full Width":
                    st.image(img_path, use_container_width=True)
                elif img_size == "Large (1200px)":
                    st.image(img_path, width=1200)
                elif img_size == "Medium (800px)":
                    st.image(img_path, width=800)
                else:
                    st.image(img_path, width=600)
                st.markdown("---")
        
        # Load comparison CSV if available
        try:
            df_comparison = pd.read_csv('MODEL_COMPARISON_VGG16_EFFICIENTNET.csv')
            st.markdown("#### üìã Tabel Perbandingan Detail")
            st.dataframe(df_comparison, use_container_width=True)
        except:
            pass
        
        st.markdown("#### üìù Kesimpulan Perbandingan")
        st.markdown("""
        **Rekomendasi**:
        - **VGG16** dipilih sebagai production model karena akurasi magnitude tertinggi (98.94%)
        - **EfficientNet-B0** cocok untuk deployment di edge devices (26√ó lebih kecil)
        - Kedua model menunjukkan LOEO validation yang konsisten (~97.5%)
        """)
    
    # ==================== PERFORMANCE METRICS ====================
    elif validation_tab == "üìâ Performance Metrics":
        st.markdown("### üìâ Detailed Performance Metrics")
        
        st.markdown("""
        **Metrik evaluasi lengkap** termasuk confusion matrix, ROC curves, 
        precision-recall curves, dan classification reports.
        """)
        
        # Sub-selection for metrics type
        metrics_type = st.radio(
            "Pilih Tipe Metrik",
            ["Confusion Matrix", "ROC Curves", "PR Curves", "Training Curves", "Dataset Analysis"],
            horizontal=True
        )
        
        st.markdown("---")
        
        if metrics_type == "Confusion Matrix":
            st.markdown("#### üìä Confusion Matrices")
            
            cm_images = [
                ('q1_evaluation_results/confusion_matrix_magnitude.png', 'Magnitude Classification'),
                ('q1_evaluation_results/confusion_matrix_magnitude_normalized.png', 'Magnitude (Normalized)'),
                ('q1_evaluation_results/confusion_matrix_azimuth.png', 'Azimuth Classification'),
                ('q1_evaluation_results/confusion_matrix_azimuth_normalized.png', 'Azimuth (Normalized)'),
                ('q1_comprehensive_report/fig9_confusion_matrices.png', 'Combined Confusion Matrices'),
            ]
            
            for img_path, title in cm_images:
                if Path(img_path).exists():
                    st.markdown(f"**{title}**")
                    if img_size == "Full Width":
                        st.image(img_path, use_container_width=True)
                    elif img_size == "Large (1200px)":
                        st.image(img_path, width=1200)
                    elif img_size == "Medium (800px)":
                        st.image(img_path, width=800)
                    else:
                        st.image(img_path, width=600)
                    st.markdown("---")
        
        elif metrics_type == "ROC Curves":
            st.markdown("#### üìà ROC Curves (Receiver Operating Characteristic)")
            
            roc_images = [
                ('q1_evaluation_results/roc_curves_magnitude.png', 'ROC Curves - Magnitude'),
                ('q1_evaluation_results/roc_curves_azimuth.png', 'ROC Curves - Azimuth'),
                ('paper_figures/fig8_roc_curves.png', 'ROC Curves Comparison'),
                ('q1_comprehensive_report/fig8_roc_auc_curves.png', 'ROC-AUC Analysis'),
            ]
            
            for img_path, title in roc_images:
                if Path(img_path).exists():
                    st.markdown(f"**{title}**")
                    if img_size == "Full Width":
                        st.image(img_path, use_container_width=True)
                    elif img_size == "Large (1200px)":
                        st.image(img_path, width=1200)
                    elif img_size == "Medium (800px)":
                        st.image(img_path, width=800)
                    else:
                        st.image(img_path, width=600)
                    st.markdown("---")
        
        elif metrics_type == "PR Curves":
            st.markdown("#### üìà Precision-Recall Curves")
            
            pr_images = [
                ('q1_evaluation_results/pr_curves_magnitude.png', 'PR Curves - Magnitude'),
                ('q1_evaluation_results/pr_curves_azimuth.png', 'PR Curves - Azimuth'),
            ]
            
            for img_path, title in pr_images:
                if Path(img_path).exists():
                    st.markdown(f"**{title}**")
                    if img_size == "Full Width":
                        st.image(img_path, use_container_width=True)
                    elif img_size == "Large (1200px)":
                        st.image(img_path, width=1200)
                    elif img_size == "Medium (800px)":
                        st.image(img_path, width=800)
                    else:
                        st.image(img_path, width=600)
                    st.markdown("---")
        
        elif metrics_type == "Training Curves":
            st.markdown("#### üìà Training Curves & Convergence")
            
            training_images = [
                ('training_report_figures/fig1_loss_curves.png', 'Loss Curves'),
                ('training_report_figures/fig2_magnitude_f1.png', 'Magnitude F1 Score'),
                ('training_report_figures/fig3_azimuth_f1.png', 'Azimuth F1 Score'),
                ('training_report_figures/fig5_training_summary.png', 'Training Summary'),
                ('q1_comprehensive_report/fig2_training_convergence.png', 'Training Convergence'),
                ('q1_comprehensive_report/fig4_training_efficiency.png', 'Training Efficiency'),
                ('q1_comprehensive_report/fig5_loss_optimization.png', 'Loss Optimization'),
                ('q1_comprehensive_report/fig7_loss_curves_detailed.png', 'Detailed Loss Curves'),
            ]
            
            for img_path, title in training_images:
                if Path(img_path).exists():
                    st.markdown(f"**{title}**")
                    if img_size == "Full Width":
                        st.image(img_path, use_container_width=True)
                    elif img_size == "Large (1200px)":
                        st.image(img_path, width=1200)
                    elif img_size == "Medium (800px)":
                        st.image(img_path, width=800)
                    else:
                        st.image(img_path, width=600)
                    st.markdown("---")
        
        else:  # Dataset Analysis
            st.markdown("#### üìä Dataset Analysis & Distribution")
            
            dataset_images = [
                ('visualizations/class_distribution.png', 'Class Distribution'),
                ('visualizations/station_distribution.png', 'Station Distribution'),
                ('visualizations/azimuth_magnitude_heatmap.png', 'Azimuth-Magnitude Heatmap'),
                ('visualizations/signal_statistics.png', 'Signal Statistics'),
                ('training_report_figures/fig4_class_distribution.png', 'Training Class Distribution'),
                ('training_report_figures/fig6_class_imbalance.png', 'Class Imbalance Analysis'),
                ('paper_figures/fig1_dataset_distribution.png', 'Dataset Distribution'),
                ('paper_figures/fig7_spectrogram_examples.png', 'Spectrogram Examples'),
                ('q1_comprehensive_report/fig1_dataset_characterization.png', 'Dataset Characterization'),
            ]
            
            for img_path, title in dataset_images:
                if Path(img_path).exists():
                    st.markdown(f"**{title}**")
                    if img_size == "Full Width":
                        st.image(img_path, use_container_width=True)
                    elif img_size == "Large (1200px)":
                        st.image(img_path, width=1200)
                    elif img_size == "Medium (800px)":
                        st.image(img_path, width=800)
                    else:
                        st.image(img_path, width=600)
                    st.markdown("---")
        
        # Classification reports
        st.markdown("#### üìã Classification Reports")
        
        col1, col2 = st.columns(2)
        
        with col1:
            try:
                df_mag = pd.read_csv('q1_evaluation_results/classification_report_magnitude.csv')
                st.markdown("**Magnitude Classification Report**")
                st.dataframe(df_mag, use_container_width=True)
            except:
                pass
        
        with col2:
            try:
                df_azi = pd.read_csv('q1_evaluation_results/classification_report_azimuth.csv')
                st.markdown("**Azimuth Classification Report**")
                st.dataframe(df_azi, use_container_width=True)
            except:
                pass

# ============================================================================
# PREKURSOR SCANNER  
# ============================================================================
elif menu == "üîç Prekursor Scanner":
    st.markdown('<div class="section-header">üîç Prekursor Scanner</div>', unsafe_allow_html=True)
    
    st.markdown("""
    **Integrated Earthquake Precursor Scanner**
    
    Scan geomagnetic data for earthquake precursor signals using the production model (v2.1, 98.94% accuracy).
    """)
    
    # Scanner mode selection
    st.markdown("### üîß Scanner Configuration")
        
        fig = go.Figure()
        fig.add_trace(go.Bar(
            name='Magnitude Accuracy',
            x=models,
            y=mag_acc,
            marker_color='#3498db',
            text=[f'{v:.2f}%' for v in mag_acc],
            textposition='outside'
        ))
        fig.add_trace(go.Bar(
            name='Azimuth Accuracy',
            x=models,
            y=azi_acc,
            marker_color='#e74c3c',
            text=[f'{v:.2f}%' for v in azi_acc],
            textposition='outside'
        ))
        fig.update_layout(
            title='Model Performance Comparison',
            xaxis_title='Model',
            yaxis_title='Accuracy (%)',
            barmode='group',
            height=500,
            yaxis=dict(range=[0, 110])
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Validation results
        st.markdown("#### üìà Cross-Validation Results (LOEO)")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("VGG16 LOEO", "97.53%", "¬±0.96%", delta_color="off")
        with col2:
            st.metric("EfficientNet LOEO", "~94%", "estimated", delta_color="off")
        with col3:
            st.metric("Xception LOEO", "~95%", "estimated", delta_color="off")
        
        # Winner analysis
        st.markdown("#### üèÜ Winner Analysis")
        
        winner_data = {
            'Metric': ['Magnitude Accuracy', 'Azimuth Accuracy', 'Model Size', 'Inference Speed', 'LOEO Validation', 'Production Ready'],
            'Winner': ['VGG16 ‚úÖ', 'VGG16 ‚úÖ', 'EfficientNet ‚úÖ', 'EfficientNet ‚úÖ', 'VGG16 ‚úÖ', 'VGG16 ‚úÖ'],
            'Score': ['98.94%', '83.92%', '20 MB', '50 ms', '97.53%', 'Deployed'],
            'Runner-up': ['Xception', 'Xception', 'Xception', 'Xception', 'Xception', 'EfficientNet']
        }
        df_winner = pd.DataFrame(winner_data)
        st.dataframe(df_winner, use_container_width=True, hide_index=True)
    
    # ==================== ARCHITECTURE COMPARISON ====================
    elif comparison_tab == "üèóÔ∏è Architecture Comparison":
        st.markdown("### üèóÔ∏è Architecture Comparison")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("#### VGG16")
            st.code("""
VGG16 Architecture (2014)
‚îú‚îÄ‚îÄ Input: 224√ó224√ó3
‚îú‚îÄ‚îÄ Conv Block 1: 64 filters
‚îú‚îÄ‚îÄ Conv Block 2: 128 filters
‚îú‚îÄ‚îÄ Conv Block 3: 256 filters
‚îú‚îÄ‚îÄ Conv Block 4: 512 filters
‚îú‚îÄ‚îÄ Conv Block 5: 512 filters
‚îú‚îÄ‚îÄ Flatten: 25,088
‚îú‚îÄ‚îÄ FC1: 4,096
‚îú‚îÄ‚îÄ FC2: 4,096
‚îî‚îÄ‚îÄ Multi-Task Heads
    ‚îú‚îÄ‚îÄ Magnitude: 4 classes
    ‚îî‚îÄ‚îÄ Azimuth: 9 classes

Total: 138M parameters
Size: 528 MB
            """)
        
        with col2:
            st.markdown("#### EfficientNet-B0")
            st.code("""
EfficientNet-B0 (2019)
‚îú‚îÄ‚îÄ Input: 224√ó224√ó3
‚îú‚îÄ‚îÄ Stem Conv: 32 filters
‚îú‚îÄ‚îÄ MBConv1: 16 filters
‚îú‚îÄ‚îÄ MBConv6: 24 filters
‚îú‚îÄ‚îÄ MBConv6: 40 filters
‚îú‚îÄ‚îÄ MBConv6: 80 filters
‚îú‚îÄ‚îÄ MBConv6: 112 filters
‚îú‚îÄ‚îÄ MBConv6: 192 filters
‚îú‚îÄ‚îÄ MBConv6: 320 filters
‚îú‚îÄ‚îÄ Head Conv: 1,280
‚îî‚îÄ‚îÄ Multi-Task Heads
    ‚îú‚îÄ‚îÄ Magnitude: 4 classes
    ‚îî‚îÄ‚îÄ Azimuth: 9 classes

Total: 5.3M parameters
Size: 20 MB
            """)
        
        with col3:
            st.markdown("#### Xception")
            st.code("""
Xception Architecture (2017)
‚îú‚îÄ‚îÄ Input: 224√ó224√ó3
‚îú‚îÄ‚îÄ Entry Flow
‚îÇ   ‚îú‚îÄ‚îÄ Conv 32 ‚Üí 64
‚îÇ   ‚îî‚îÄ‚îÄ SepConv blocks
‚îú‚îÄ‚îÄ Middle Flow
‚îÇ   ‚îî‚îÄ‚îÄ 8√ó SepConv blocks
‚îú‚îÄ‚îÄ Exit Flow
‚îÇ   ‚îî‚îÄ‚îÄ SepConv 1024‚Üí2048
‚îú‚îÄ‚îÄ Global Avg Pool
‚îî‚îÄ‚îÄ Multi-Task Heads
    ‚îú‚îÄ‚îÄ Magnitude: 4 classes
    ‚îî‚îÄ‚îÄ Azimuth: 9 classes

Total: 22.9M parameters
Size: 88 MB
            """)
        
        st.markdown("---")
        st.markdown("#### üîë Key Architectural Differences")
        
        arch_diff = {
            'Feature': ['Convolution Type', 'Skip Connections', 'Attention Mechanism', 'Activation', 'Normalization', 'Depth'],
            'VGG16': ['Standard Conv', 'No', 'No', 'ReLU', 'BatchNorm', '16 layers'],
            'EfficientNet-B0': ['Depthwise Separable', 'Yes (MBConv)', 'SE Blocks', 'SiLU/Swish', 'BatchNorm', 'Compound scaled'],
            'Xception': ['Depthwise Separable', 'Yes', 'No', 'ReLU', 'BatchNorm', '36 layers']
        }
        df_arch = pd.DataFrame(arch_diff)
        st.dataframe(df_arch, use_container_width=True, hide_index=True)
    
    # ==================== EFFICIENCY ANALYSIS ====================
    elif comparison_tab == "‚ö° Efficiency Analysis":
        st.markdown("### ‚ö° Efficiency Analysis")
        
        # Size comparison
        st.markdown("#### üì¶ Model Size Comparison")
        
        models = ['VGG16', 'EfficientNet-B0', 'Xception']
        sizes = [528, 20, 88]
        params = [138, 5.3, 22.9]
        
        fig = go.Figure()
        fig.add_trace(go.Bar(
            name='Model Size (MB)',
            x=models,
            y=sizes,
            marker_color=['#e74c3c', '#2ecc71', '#f39c12'],
            text=[f'{v} MB' for v in sizes],
            textposition='outside'
        ))
        fig.update_layout(
            title='Model Size Comparison',
            xaxis_title='Model',
            yaxis_title='Size (MB)',
            height=400
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Parameters comparison
        st.markdown("#### üî¢ Parameters Comparison")
        
        fig2 = go.Figure()
        fig2.add_trace(go.Bar(
            name='Parameters (Millions)',
            x=models,
            y=params,
            marker_color=['#e74c3c', '#2ecc71', '#f39c12'],
            text=[f'{v}M' for v in params],
            textposition='outside'
        ))
        fig2.update_layout(
            title='Model Parameters Comparison',
            xaxis_title='Model',
            yaxis_title='Parameters (Millions)',
            height=400
        )
        st.plotly_chart(fig2, use_container_width=True)
        
        # Efficiency metrics table
        st.markdown("#### üìä Efficiency Metrics")
        
        eff_data = {
            'Metric': ['Model Size', 'Parameters', 'Inference Time', 'Memory Usage', 'FLOPs', 'Mobile Ready'],
            'VGG16': ['528 MB', '138M', '~125 ms', '~2 GB', '~15.5 GFLOPs', '‚ùå No'],
            'EfficientNet-B0': ['20 MB ‚úÖ', '5.3M ‚úÖ', '~50 ms ‚úÖ', '~500 MB ‚úÖ', '~0.39 GFLOPs ‚úÖ', '‚úÖ Yes'],
            'Xception': ['88 MB', '22.9M', '~75 ms', '~1 GB', '~8.4 GFLOPs', '‚ö†Ô∏è Limited'],
            'Winner': ['EfficientNet', 'EfficientNet', 'EfficientNet', 'EfficientNet', 'EfficientNet', 'EfficientNet']
        }
        df_eff = pd.DataFrame(eff_data)
        st.dataframe(df_eff, use_container_width=True, hide_index=True)
        
        # Efficiency score
        st.markdown("#### üéØ Efficiency Score (Accuracy per MB)")
        
        eff_scores = [98.94/528*100, 94.37/20*100, 97.0/88*100]
        
        fig3 = go.Figure()
        fig3.add_trace(go.Bar(
            x=models,
            y=eff_scores,
            marker_color=['#e74c3c', '#2ecc71', '#f39c12'],
            text=[f'{v:.1f}' for v in eff_scores],
            textposition='outside'
        ))
        fig3.update_layout(
            title='Efficiency Score (Accuracy % per MB √ó 100)',
            xaxis_title='Model',
            yaxis_title='Efficiency Score',
            height=400
        )
        st.plotly_chart(fig3, use_container_width=True)
        
        st.info("**EfficientNet-B0** memiliki efficiency score tertinggi (471.9), menunjukkan rasio akurasi per ukuran model terbaik.")
    
    # ==================== STRENGTHS & WEAKNESSES ====================
    elif comparison_tab == "‚úÖ Strengths & Weaknesses":
        st.markdown("### ‚úÖ Strengths & Weaknesses")
        
        # VGG16
        st.markdown("#### üîµ VGG16")
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown('<div class="success-box">', unsafe_allow_html=True)
            st.markdown("""
            **‚úÖ Kelebihan (Strengths)**
            
            1. **Akurasi Tertinggi** - 98.94% magnitude
            2. **Azimuth Terbaik** - 83.92% (setelah final training)
            3. **LOEO Validated** - 97.53% ¬± 0.96%
            4. **Arsitektur Sederhana** - Mudah dipahami
            5. **Stabil** - Konsisten di berbagai kondisi
            6. **Production Proven** - Sudah deployed
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="warning-box">', unsafe_allow_html=True)
            st.markdown("""
            **‚ùå Kekurangan (Weaknesses)**
            
            1. **Ukuran Besar** - 528 MB
            2. **Parameter Banyak** - 138M
            3. **Inference Lambat** - ~125 ms
            4. **Memory Tinggi** - ~2 GB GPU
            5. **Tidak Mobile-Friendly**
            6. **Arsitektur Lama** - 2014
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        st.markdown("---")
        
        # EfficientNet
        st.markdown("#### üü¢ EfficientNet-B0")
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown('<div class="success-box">', unsafe_allow_html=True)
            st.markdown("""
            **‚úÖ Kelebihan (Strengths)**
            
            1. **Paling Efisien** - 20 MB (26√ó lebih kecil)
            2. **Inference Cepat** - ~50 ms (2.5√ó lebih cepat)
            3. **Mobile Ready** - Bisa deploy ke edge
            4. **Modern Architecture** - 2019
            5. **Low Memory** - ~500 MB GPU
            6. **Compound Scaling** - Optimal design
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="warning-box">', unsafe_allow_html=True)
            st.markdown("""
            **‚ùå Kekurangan (Weaknesses)**
            
            1. **Akurasi Lebih Rendah** - 94.37% magnitude
            2. **Azimuth Rendah** - 57.39%
            3. **Perlu Tuning** - Hyperparameter optimization
            4. **Training Lebih Lama** - Dengan tuning
            5. **Kompleksitas Arsitektur**
            6. **Belum LOEO Validated**
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        st.markdown("---")
        
        # Xception
        st.markdown("#### üü° Xception")
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown('<div class="success-box">', unsafe_allow_html=True)
            st.markdown("""
            **‚úÖ Kelebihan (Strengths)**
            
            1. **Balance Size-Accuracy** - 88 MB
            2. **Depthwise Separable** - Efficient convolutions
            3. **Good Accuracy** - ~96-98% magnitude
            4. **Moderate Speed** - ~75 ms
            5. **Skip Connections** - Better gradients
            6. **Proven in ImageNet**
            """)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="warning-box">', unsafe_allow_html=True)
            st.markdown("""
            **‚ùå Kekurangan (Weaknesses)**
            
            1. **Middle Ground** - Tidak terbaik di aspek apapun
            2. **Azimuth Moderate** - ~55-65%
            3. **Belum Fully Tested**
            4. **Perlu SMOTE** - Class balancing
            5. **Limited Mobile Support**
            6. **Research Stage**
            """)
            st.markdown('</div>', unsafe_allow_html=True)
    
    # ==================== USE CASE RECOMMENDATIONS ====================
    elif comparison_tab == "üéØ Use Case Recommendations":
        st.markdown("### üéØ Use Case Recommendations")
        
        st.markdown("#### üìã Kapan Menggunakan Model Mana?")
        
        # Use case table
        use_cases = {
            'Use Case': [
                'üî¨ Research & Analysis',
                'üè≠ Production Server',
                'üì± Mobile Deployment',
                '‚ö° Real-time Processing',
                'üí∞ Resource-Constrained',
                'üéØ Maximum Accuracy',
                'üîÑ Ensemble Learning',
                'üìä Publication/Paper'
            ],
            'Recommended Model': [
                'VGG16 ‚úÖ',
                'VGG16 ‚úÖ',
                'EfficientNet-B0 ‚úÖ',
                'EfficientNet-B0 ‚úÖ',
                'EfficientNet-B0 ‚úÖ',
                'VGG16 ‚úÖ',
                'All Three',
                'VGG16 + EfficientNet'
            ],
            'Reason': [
                'Highest accuracy, validated',
                'Proven, stable, deployed',
                'Small size (20 MB), fast',
                'Fastest inference (50 ms)',
                'Lowest memory & storage',
                '98.94% magnitude accuracy',
                'Diversity improves results',
                'Compare architectures'
            ]
        }
        df_use = pd.DataFrame(use_cases)
        st.dataframe(df_use, use_container_width=True, hide_index=True)
        
        st.markdown("---")
        
        # Decision flowchart
        st.markdown("#### üîÄ Decision Flowchart")
        
        st.markdown("""
        ```
        START
          ‚îÇ
          ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ Butuh akurasi maksimum?     ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ YES              ‚îÇ NO
          ‚ñº                  ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ VGG16   ‚îÇ    ‚îÇ Butuh deploy ke mobile/edge?‚îÇ
        ‚îÇ (98.94%)‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ YES              ‚îÇ NO
                         ‚ñº                  ‚ñº
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚îÇ EfficientNet‚îÇ    ‚îÇ Butuh balance size-accuracy?‚îÇ
                   ‚îÇ (20 MB)     ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ YES              ‚îÇ NO
                                        ‚ñº                  ‚ñº
                                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                  ‚îÇ Xception‚îÇ        ‚îÇ VGG16   ‚îÇ
                                  ‚îÇ (88 MB) ‚îÇ        ‚îÇ (Best)  ‚îÇ
                                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ```
        """)
        
        st.markdown("---")
        
        # Final recommendation
        st.markdown("#### üèÜ Rekomendasi Final")
        
        st.markdown('<div class="success-box">', unsafe_allow_html=True)
        st.markdown("""
        **Untuk Project Ini: VGG16 adalah Pilihan Terbaik**
        
        ‚úÖ **Alasan Utama**:
        1. Akurasi tertinggi (98.94% magnitude, 83.92% azimuth)
        2. Sudah divalidasi dengan LOEO (97.53%)
        3. Sudah deployed dan proven di production
        4. Stabil dan konsisten
        
        ‚ö° **Alternative untuk Edge/Mobile**: EfficientNet-B0
        - Jika perlu deploy ke perangkat dengan resource terbatas
        - Trade-off: akurasi sedikit lebih rendah (94.37%)
        """)
        st.markdown('</div>', unsafe_allow_html=True)
    
    # ==================== DETAILED METRICS TABLE ====================
    elif comparison_tab == "üìà Detailed Metrics Table":
        st.markdown("### üìà Detailed Metrics Table")
        
        st.markdown("#### üìä Complete Comparison Table")
        
        # Comprehensive comparison data
        detailed_data = {
            'Category': [
                'PERFORMANCE', 'PERFORMANCE', 'PERFORMANCE', 'PERFORMANCE', 'PERFORMANCE',
                'ARCHITECTURE', 'ARCHITECTURE', 'ARCHITECTURE', 'ARCHITECTURE',
                'EFFICIENCY', 'EFFICIENCY', 'EFFICIENCY', 'EFFICIENCY', 'EFFICIENCY',
                'VALIDATION', 'VALIDATION', 'VALIDATION',
                'DEPLOYMENT', 'DEPLOYMENT', 'DEPLOYMENT'
            ],
            'Metric': [
                'Magnitude Accuracy', 'Azimuth Accuracy', 'Combined Accuracy', 'Normal Detection', 'F1-Score (Mag)',
                'Total Parameters', 'Model Size', 'Architecture Year', 'Convolution Type',
                'Inference Time', 'Memory Usage', 'FLOPs', 'Mobile Ready', 'Training Time',
                'LOEO Magnitude', 'LOEO Azimuth', 'LOSO Magnitude',
                'Production Status', 'Scalability', 'Edge Deployment'
            ],
            'VGG16': [
                '98.94%', '83.92%', '91.43%', '100%', '0.98',
                '138M', '528 MB', '2014', 'Standard',
                '~125 ms', '~2 GB', '15.5 GFLOPs', '‚ùå', '2.3 hours',
                '97.53%', '69.51%', '97.57%',
                '‚úÖ Deployed', 'Limited', '‚ùå'
            ],
            'EfficientNet-B0': [
                '94.37%', '57.39%', '75.88%', '100%', '0.94',
                '5.3M', '20 MB', '2019', 'Depthwise Sep',
                '~50 ms', '~500 MB', '0.39 GFLOPs', '‚úÖ', '3.8 hours',
                '~94%', '~55%', '~94%',
                'Alternative', 'Excellent', '‚úÖ'
            ],
            'Xception': [
                '~97%', '~60%', '~78%', '~100%', '~0.96',
                '22.9M', '88 MB', '2017', 'Depthwise Sep',
                '~75 ms', '~1 GB', '8.4 GFLOPs', '‚ö†Ô∏è', '~3 hours',
                '~95%', '~58%', '~95%',
                'Research', 'Good', '‚ö†Ô∏è'
            ],
            'Winner': [
                'VGG16 ‚úÖ', 'VGG16 ‚úÖ', 'VGG16 ‚úÖ', 'Tie', 'VGG16 ‚úÖ',
                'EfficientNet ‚úÖ', 'EfficientNet ‚úÖ', 'EfficientNet ‚úÖ', 'Tie',
                'EfficientNet ‚úÖ', 'EfficientNet ‚úÖ', 'EfficientNet ‚úÖ', 'EfficientNet ‚úÖ', 'VGG16 ‚úÖ',
                'VGG16 ‚úÖ', 'VGG16 ‚úÖ', 'VGG16 ‚úÖ',
                'VGG16 ‚úÖ', 'EfficientNet ‚úÖ', 'EfficientNet ‚úÖ'
            ]
        }
        
        df_detailed = pd.DataFrame(detailed_data)
        st.dataframe(df_detailed, use_container_width=True, hide_index=True)
        
        # Download button
        csv = df_detailed.to_csv(index=False)
        st.download_button(
            label="üì• Download Comparison Table (CSV)",
            data=csv,
            file_name="model_comparison_detailed.csv",
            mime="text/csv"
        )
        
        st.markdown("---")
        
        # Summary statistics
        st.markdown("#### üìä Summary Statistics")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("**VGG16 Wins:**")
            st.metric("Categories Won", "11/20", "55%")
        
        with col2:
            st.markdown("**EfficientNet Wins:**")
            st.metric("Categories Won", "8/20", "40%")
        
        with col3:
            st.markdown("**Xception Wins:**")
            st.metric("Categories Won", "0/20", "0%")
        
        st.markdown("---")
        
        # Final verdict
        st.markdown("#### üèÜ Final Verdict")
        
        st.markdown("""
        | Aspect | Winner | Score |
        |--------|--------|-------|
        | **Overall Accuracy** | VGG16 | 98.94% |
        | **Efficiency** | EfficientNet-B0 | 26√ó smaller |
        | **Production** | VGG16 | Deployed & Validated |
        | **Mobile/Edge** | EfficientNet-B0 | 20 MB, 50 ms |
        | **Research** | VGG16 | Best results |
        
        **üèÜ Overall Winner: VGG16** - Best accuracy, validated, production-ready
        
        **‚ö° Efficiency Winner: EfficientNet-B0** - Best for resource-constrained deployment
        """)

# ============================================================================
# PREKURSOR SCANNER
# ============================================================================
elif menu == "üîç Prekursor Scanner":
    st.markdown('<div class="section-header">üîç Prekursor Scanner</div>', unsafe_allow_html=True)
    
    st.markdown("""
    **Integrated Earthquake Precursor Scanner**
    
    Scan geomagnetic data for earthquake precursor signals using the production model (v2.1, 98.94% accuracy).
    """)
    
    # Scanner mode selection
    st.markdown("### üîß Scanner Configuration")
    
    col1, col2 = st.columns(2)
    
    with col1:
        scanner_mode = st.radio(
            "Data Source",
            ["üåê SSH Server (Unlimited)", "üíæ Local Files (Limited)"],
            help="SSH: Access full server data | Local: Use cached files only"
        )
    
    with col2:
        if scanner_mode == "üåê SSH Server (Unlimited)":
            st.info("""
            **SSH Server Mode**
            - Access to full historical data
            - Requires internet connection
            - Server: 202.90.198.224:4343
            """)
        else:
            st.info("""
            **Local Files Mode**
            - Uses cached data (mdata2/)
            - Works offline
            - Limited date range
            """)
    
    st.markdown("---")
    st.markdown("### üìä Scan Parameters")
    
    # Scanner interface
    col1, col2 = st.columns(2)
    
    with col1:
        station = st.selectbox(
            "Select Station",
            ["GTO", "SCN", "MLB", "ALR", "AMB", "CLP", "GSI", "JYP", "KPY", "LPS", 
             "LUT", "LWA", "LWK", "PLU", "SBG", "SKB", "SMI", "SRG", "SRO", "TND", 
             "TNT", "TRD", "TRT", "YOG"],
            help="GTO recommended for SSH mode"
        )
    
    with col2:
        # Default date based on mode
        if scanner_mode == "üåê SSH Server (Unlimited)":
            default_date = datetime(2026, 1, 13)  # Recent date for SSH
        else:
            default_date = datetime(2018, 1, 17)  # Known local date
        
        date = st.date_input("Select Date", default_date)
    
    if st.button("üîç Scan for Precursors", type="primary"):
        with st.spinner("Scanning..."):
            try:
                import traceback
                date_str = date.strftime("%Y-%m-%d")
                
                # Choose scanner based on mode
                if scanner_mode == "üåê SSH Server (Unlimited)":
                    st.info(f"üì° Connecting to SSH server and scanning {station} on {date_str}...")
                    st.warning("‚è≥ First scan may take 15-30 seconds (SSH connection + data download)")
                    
                    from prekursor_scanner_production import PrekursorScannerProduction
                    
                    # Initialize SSH scanner
                    scanner = PrekursorScannerProduction()
                    
                    # Create output directory
                    output_dir = Path('scanner_results')
                    output_dir.mkdir(exist_ok=True)
                    
                    # Run scan
                    result = scanner.scan(date_str, station, save_results=True)
                    
                else:  # Local mode
                    st.info(f"üìÇ Scanning local data for {station} on {date_str}...")
                    
                    from scanner_local_wrapper import LocalScannerWrapper
                    
                    # Initialize local scanner
                    scanner = LocalScannerWrapper()
                    
                    # Create output directory
                    output_dir = Path('scanner_results')
                    output_dir.mkdir(exist_ok=True)
                    save_path = output_dir / f"scan_{station}_{date_str.replace('-', '')}.png"
                    
                    # Run scan
                    result = scanner.scan(date_str, station, save_path=str(save_path))
                
                # Process results
                if result and 'predictions' in result:
                    st.markdown("---")
                    st.markdown("### üìä Scan Results")
                    
                    predictions = result['predictions']
                    
                    # Display results
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                        mag_class = predictions['magnitude']['class_name']
                        mag_conf = predictions['magnitude']['confidence']
                        st.metric("Magnitude", mag_class, f"{mag_conf:.1f}% confidence")
                        st.markdown('</div>', unsafe_allow_html=True)
                    
                    with col2:
                        st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                        azi_class = predictions['azimuth']['class_name']
                        azi_conf = predictions['azimuth']['confidence']
                        st.metric("Azimuth", azi_class, f"{azi_conf:.1f}% confidence")
                        st.markdown('</div>', unsafe_allow_html=True)
                    
                    with col3:
                        is_precursor = predictions['is_precursor']
                        status = "‚ö†Ô∏è PRECURSOR" if is_precursor else "‚úÖ NORMAL"
                        st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                        st.metric("Status", status)
                        st.markdown('</div>', unsafe_allow_html=True)
                    
                    # Show spectrogram
                    st.markdown("### üìà Spectrogram")
                    
                    # Image size selector
                    col_size1, col_size2 = st.columns([1, 3])
                    with col_size1:
                        image_size = st.selectbox(
                            "Image Size",
                            ["Large (Full Width)", "Medium (1200px)", "Small (800px)"],
                            index=0
                        )
                    
                    # Try to find spectrogram image
                    possible_paths = [
                        Path(f"scanner_results/scan_{station}_{date_str.replace('-', '')}_v2.png"),
                        Path(f"scanner_results/scan_{station}_{date_str.replace('-', '')}.png"),
                        Path(f"scanner_results/{station}_{date_str}_scan.png"),
                    ]
                    
                    image_found = False
                    for img_path in possible_paths:
                        if img_path.exists():
                            if image_size == "Large (Full Width)":
                                st.image(str(img_path), use_container_width=True, caption=f"{station} - {date_str}")
                            elif image_size == "Medium (1200px)":
                                st.image(str(img_path), width=1200, caption=f"{station} - {date_str}")
                            else:
                                st.image(str(img_path), width=800, caption=f"{station} - {date_str}")
                            image_found = True
                            break
                    
                    if not image_found and 'spectrogram' in result:
                        if image_size == "Large (Full Width)":
                            st.image(result['spectrogram'], use_container_width=True, caption=f"{station} - {date_str}")
                        elif image_size == "Medium (1200px)":
                            st.image(result['spectrogram'], width=1200, caption=f"{station} - {date_str}")
                        else:
                            st.image(result['spectrogram'], width=800, caption=f"{station} - {date_str}")
                        image_found = True
                    
                    if not image_found:
                        st.warning("Spectrogram image not saved (prediction completed)")
                    
                    # Download button for image
                    if image_found:
                        for img_path in possible_paths:
                            if img_path.exists():
                                with open(img_path, 'rb') as f:
                                    st.download_button(
                                        label="üì• Download Spectrogram",
                                        data=f,
                                        file_name=f"spectrogram_{station}_{date_str}.png",
                                        mime="image/png"
                                    )
                                break
                    
                    # Data quality info
                    if 'data_quality' in result:
                        st.markdown("### üìä Data Quality")
                        quality = result['data_quality']
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("Coverage", f"{quality.get('coverage', 0):.1f}%")
                        with col2:
                            st.metric("Valid Samples", f"{quality.get('valid_samples', 0):,}")
                        with col3:
                            st.metric("H Mean", f"{quality.get('h_mean', 0):.1f} nT")
                    
                    # Success message
                    st.success(f"‚úÖ Scan completed successfully!")
                    
                    # Show data source info
                    if scanner_mode == "üåê SSH Server (Unlimited)":
                        st.info("üì° Data fetched from SSH server (202.90.198.224:4343)")
                    else:
                        st.info("üíæ Data loaded from local cache (mdata2/)")
                    
                else:
                    st.error("‚ùå Scan failed - No data available")
                    
                    if scanner_mode == "üåê SSH Server (Unlimited)":
                        st.warning(f"""
                        **SSH Connection Failed**
                        
                        Possible causes:
                        - Server is down or unreachable
                        - Network connection issue
                        - Data file not found on server for {station} on {date_str}
                        
                        **Try**:
                        - Check internet connection
                        - Try different station (GTO recommended)
                        - Try recent date (e.g., 2026-01-13)
                        - Switch to Local mode if you have cached data
                        """)
                    else:
                        st.warning(f"""
                        **Local Data Not Found**
                        
                        File not found: `mdata2/{station}/S{date.strftime('%y%m%d')}.{station}.gz`
                        
                        **Available local data for SCN**:
                        - 2018: Full year
                        - 2019: Full year
                        - 2020: Jan-May
                        - 2023: Jan 1-2
                        
                        **Try**:
                        - Use SSH Server mode for unlimited access
                        - Try date: 2018-01-17 (SCN) with Local mode
                        """)
            
            except Exception as e:
                st.error(f"‚ùå Error: {str(e)}")
                
                with st.expander("Show detailed error"):
                    st.code(traceback.format_exc())
                
                st.info("""
                **Troubleshooting**:
                
                **SSH Mode**:
                - Check internet connection
                - Verify server is accessible: 202.90.198.224:4343
                - Try different station or date
                
                **Local Mode**:
                - Check data exists: `mdata2/{STATION}/S{YYMMDD}.{STATION}.gz`
                - Try SCN station with 2018-01-17
                
                **General**:
                - Model exists: `experiments_fixed/exp_fixed_20260202_163643/best_model.pth`
                - Dependencies installed: `pip install paramiko torch torchvision`
                """)

# ============================================================================
# REAL-TIME MONITORING
# ============================================================================
elif menu == "üì° Real-time Monitoring":
    st.markdown('<div class="section-header">üì° Real-time Monitoring</div>', unsafe_allow_html=True)
    
    st.markdown("""
    **Production Monitoring Dashboard**
    
    For full real-time monitoring with auto-refresh, use the Flask dashboard:
    """)
    
    st.code("""
# Start Flask dashboard
python production/scripts/web_dashboard.py

# Open in browser
http://localhost:5000
    """)
    
    st.markdown("---")
    
    # Show recent predictions if available
    st.markdown("### üìä Recent Predictions")
    
    predictions_file = Path('production/monitoring/predictions_log.csv')
    
    if predictions_file.exists():
        df = pd.read_csv(predictions_file)
        
        if len(df) > 0:
            st.dataframe(df.tail(10), use_container_width=True)
        else:
            st.info("No predictions yet. Run scanner to see data.")
    else:
        st.info("No predictions log found. Run scanner to create log.")

# ============================================================================
# DOCUMENTATION
# ============================================================================
elif menu == "üìñ Documentation":
    st.markdown('<div class="section-header">üìñ Documentation</div>', unsafe_allow_html=True)
    
    st.markdown("""
    ### üìö Available Documentation
    
    **Production System**:
    - `production/docs/OPERATIONAL_GUIDE.md` - Complete operations manual
    - `production/docs/DASHBOARD_ACCESS_GUIDE.md` - Dashboard access guide
    - `production/PRODUCTION_READY_SUMMARY.md` - System overview
    
    **Training & Evaluation**:
    - `FINAL_EVALUATION_RESULTS.md` - Model evaluation results
    - `TRAINING_COMPLETE_FINAL_RESULTS.md` - Training summary
    - `DATA_LEAKAGE_CRITICAL_FINDING.md` - Data leakage fix
    
    **Deployment**:
    - `PRODUCTION_DEPLOYMENT_FINAL.md` - Deployment summary
    - `CLEANUP_COMPLETE_SUMMARY.md` - Cleanup summary
    
    ### üöÄ Quick Start
    
    **Run Scanner**:
    ```bash
    python prekursor_scanner_production.py --station SCN --date 2018-01-17
    ```
    
    **Start Dashboard**:
    ```bash
    # Streamlit (this dashboard)
    streamlit run project_dashboard_v2.py
    
    # Flask (real-time monitoring)
    python production/scripts/web_dashboard.py
    ```
    
    **Monitor Performance**:
    ```bash
    python production/scripts/monitor_production_performance.py --report
    ```
    """)
    
    st.markdown("---")
    
    st.markdown("### üìä System Status")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown('<div class="success-box">', unsafe_allow_html=True)
        st.markdown("""
        **‚úÖ Production Status**
        - Model: v2.1 (98.94%)
        - Status: ACTIVE
        - Data Leakage: FIXED
        - LOEO/LOSO: VALIDATED
        - Deployment: COMPLETE
        """)
        st.markdown('</div>', unsafe_allow_html=True)
    
    with col2:
        st.markdown('<div class="info-box">', unsafe_allow_html=True)
        st.markdown("""
        **üìä System Info**
        - Framework: PyTorch
        - Dashboard: Streamlit + Flask
        - Scanner: Integrated
        - Monitoring: Real-time
        """)
        st.markdown('</div>', unsafe_allow_html=True)

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
    <p>Earthquake Prediction System V2.1 | Production Model (98.94% Accuracy) | LOEO/LOSO Validated</p>
    <p>¬© 2026 Earthquake Prediction Research Team</p>
</div>
""", unsafe_allow_html=True)
